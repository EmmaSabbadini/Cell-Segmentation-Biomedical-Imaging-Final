{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train_cyclegan.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"v-dvh4MB8BA-","colab_type":"code","outputId":"a721783e-e2fc-4dd9-d19d-455144c8c945","executionInfo":{"status":"ok","timestamp":1575175147377,"user_tz":300,"elapsed":17686,"user":{"displayName":"Md Hasib Zunair 1320262643","photoUrl":"","userId":"12069756592370329757"}},"colab":{"base_uri":"https://localhost:8080/","height":124}},"source":["# save files in drive\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"w_z3ezz-IMpA","colab_type":"code","outputId":"28da7496-2056-422d-d1ae-3fc70b5a2ddc","executionInfo":{"status":"ok","timestamp":1574125249589,"user_tz":300,"elapsed":23878,"user":{"displayName":"Md Hasib Zunair 1320262643","photoUrl":"","userId":"12069756592370329757"}},"colab":{"base_uri":"https://localhost:8080/","height":538}},"source":["# keras-contrib install\n","!pip install git+https://www.github.com/keras-team/keras-contrib.git\n","!pip install scipy==1.2.1\n","!pip install pillow"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting git+https://www.github.com/keras-team/keras-contrib.git\n","  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-sa1y86jy\n","  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-sa1y86jy\n","Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-contrib==2.0.8) (2.2.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (3.13)\n","Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.0.8)\n","Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.1.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (2.8.0)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.3.2)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.12.0)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.17.4)\n","Building wheels for collected packages: keras-contrib\n","  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-cp36-none-any.whl size=101065 sha256=375983086d6aad8ab2db2561a5c124a29133e25f3efacd3b4dcd94615f5d00dd\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-kjibnt5a/wheels/11/27/c8/4ed56de7b55f4f61244e2dc6ef3cdbaff2692527a2ce6502ba\n","Successfully built keras-contrib\n","Installing collected packages: keras-contrib\n","Successfully installed keras-contrib-2.0.8\n","Collecting scipy==1.2.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7f/5f/c48860704092933bf1c4c1574a8de1ffd16bf4fde8bab190d747598844b2/scipy-1.2.1-cp36-cp36m-manylinux1_x86_64.whl (24.8MB)\n","\u001b[K     |████████████████████████████████| 24.8MB 1.3MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy==1.2.1) (1.17.4)\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Installing collected packages: scipy\n","  Found existing installation: scipy 1.3.2\n","    Uninstalling scipy-1.3.2:\n","      Successfully uninstalled scipy-1.3.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WTxxUPd7Kmur","colab_type":"code","outputId":"249b3372-a378-4ab8-fee5-5bb4f280dd9f","executionInfo":{"status":"ok","timestamp":1574125260114,"user_tz":300,"elapsed":570,"user":{"displayName":"Md Hasib Zunair 1320262643","photoUrl":"","userId":"12069756592370329757"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["import scipy.misc\n","scipy.misc.imread"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<function numpy.lib.utils._Deprecate.__call__.<locals>.newfunc>"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"22GV37958mGO","colab_type":"code","outputId":"df490931-d466-41c6-a7db-d5305a243685","executionInfo":{"status":"ok","timestamp":1574125431209,"user_tz":300,"elapsed":804,"user":{"displayName":"Md Hasib Zunair 1320262643","photoUrl":"","userId":"12069756592370329757"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["# set paths\n","import os\n","import tensorflow as tf\n","import scipy\n","from glob import glob\n","import numpy as np\n","\n","print(tf.test.gpu_device_name())\n","\n","base_path = os.path.abspath(\"gdrive/My Drive/work/\")\n","dataset_path = os.path.join(base_path, \"datasets/isic2016gan\")\n","model_path = os.path.join(base_path, \"models\")\n","print(os.listdir(dataset_path))\n","\n","\n","class DataLoader():\n","    def __init__(self, dataset_name, img_res=(256, 256)): #128\n","        self.dataset_name = dataset_name\n","        self.img_res = img_res\n","\n","    def load_data(self, domain, batch_size=1, is_testing=False):\n","        data_type = \"train%s\" % domain if not is_testing else \"test%s\" % domain\n","        path = glob('{}/datasets/%s/%s/*'.format(base_path) % (self.dataset_name, data_type))\n","\n","        batch_images = np.random.choice(path, size=batch_size)\n","\n","        imgs = []\n","        for img_path in batch_images:\n","            img = self.imread(img_path)\n","            if not is_testing:\n","                img = scipy.misc.imresize(img, self.img_res)\n","\n","                if np.random.random() > 0.5:\n","                    img = np.fliplr(img)\n","            else:\n","                img = scipy.misc.imresize(img, self.img_res)\n","            imgs.append(img)\n","\n","        # rescale to [-1, 1]\n","        imgs = np.array(imgs)/127.5 - 1.\n","        \n","        # rescale to [0, 1]\n","        #imgs = imgs.astype('float32')\n","        #imgs = np.array(imgs)\n","        #imgs = imgs / 255.\n","        \n","        return imgs\n","\n","    def load_batch(self, batch_size=1, is_testing=False):\n","        data_type = \"train\" if not is_testing else \"val\"\n","        path_A = glob('{}/datasets/%s/%sA/*'.format(base_path) % (self.dataset_name, data_type))\n","        path_B = glob('{}/datasets/%s/%sB/*'.format(base_path) % (self.dataset_name, data_type))\n","\n","        self.n_batches = int(min(len(path_A), len(path_B)) / batch_size)\n","        total_samples = self.n_batches * batch_size\n","\n","        # Sample n_batches * batch_size from each path list so that model sees all\n","        # samples from both domains\n","        path_A = np.random.choice(path_A, total_samples, replace=False)\n","        path_B = np.random.choice(path_B, total_samples, replace=False)\n","\n","        for i in range(self.n_batches-1):\n","            batch_A = path_A[i*batch_size:(i+1)*batch_size]\n","            batch_B = path_B[i*batch_size:(i+1)*batch_size]\n","            imgs_A, imgs_B = [], []\n","            for img_A, img_B in zip(batch_A, batch_B):\n","                img_A = self.imread(img_A)\n","                img_B = self.imread(img_B)\n","\n","                img_A = scipy.misc.imresize(img_A, self.img_res)\n","                img_B = scipy.misc.imresize(img_B, self.img_res)\n","\n","                if not is_testing and np.random.random() > 0.5:\n","                        img_A = np.fliplr(img_A)\n","                        img_B = np.fliplr(img_B)\n","\n","                imgs_A.append(img_A)\n","                imgs_B.append(img_B)\n","\n","            # rescale to [-1, 1]\n","            imgs_A = np.array(imgs_A)/127.5 - 1.\n","            imgs_B = np.array(imgs_B)/127.5 - 1.\n","\n","            # rescale to [0, 1]\n","            \n","            #imgs_A = imgs_A.astype('float32')\n","            #imgs_A = np.array(imgs_A)\n","            #imgs_A = imgs_A / 255.\n","            \n","            #imgs_B = imgs_B.astype('float32')\n","            #imgs_B = np.array(imgs_B)\n","            #imgs_B = imgs_B / 255.\n","            \n","            yield imgs_A, imgs_B\n","\n","    def load_img(self, path):\n","        img = self.imread(path)\n","        img = scipy.misc.imresize(img, self.img_res)\n","        \n","        # rescale to [-1, 1]\n","        img = img/127.5 - 1.\n","        \n","        # rescale to [0, 1]\n","        #img = img.astype('float32')\n","        #img = img / 255.\n","        \n","        return img[np.newaxis, :, :, :]\n","\n","    def imread(self, path):\n","        return scipy.misc.imread(path, mode='RGB').astype(np.float) # np.float"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/device:GPU:0\n","['testB', 'trainA', 'testA', 'trainB']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2T6J9i-EF3-C","colab_type":"code","outputId":"5f97d94b-3dfd-4b03-e70a-5a51391c345a","executionInfo":{"status":"ok","timestamp":1574125433086,"user_tz":300,"elapsed":795,"user":{"displayName":"Md Hasib Zunair 1320262643","photoUrl":"","userId":"12069756592370329757"}},"colab":{"base_uri":"https://localhost:8080/","height":72}},"source":["path = glob('{}/datasets/%s/%s/*'.format(base_path) % (\"isic2016gan\", \"trainB\"))\n","path[:3]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['/content/gdrive/My Drive/work/datasets/isic2016gan/trainB/cancer104.jpeg',\n"," '/content/gdrive/My Drive/work/datasets/isic2016gan/trainB/cancer97.jpeg',\n"," '/content/gdrive/My Drive/work/datasets/isic2016gan/trainB/cancer363.jpeg']"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"dzGnIWJt8_Q0","colab_type":"code","outputId":"facff5f5-2b2c-495e-c504-d1f7a772067c","executionInfo":{"status":"ok","timestamp":1574139369723,"user_tz":300,"elapsed":13935326,"user":{"displayName":"Md Hasib Zunair 1320262643","photoUrl":"","userId":"12069756592370329757"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["from __future__ import print_function, division\n","import scipy\n","from keras.datasets import mnist\n","from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n","from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n","from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n","from keras.layers.advanced_activations import LeakyReLU\n","from keras.layers.convolutional import UpSampling2D, Conv2D\n","from keras.models import Sequential, Model\n","from keras.optimizers import Adam\n","import datetime\n","import matplotlib.pyplot as plt\n","import sys\n","import numpy as np\n","import os\n","import keras\n","import pandas as pd\n","import time\n","\n","class CycleGAN():\n","    def __init__(self):\n","        # Input shape\n","        self.img_rows = 256 \n","        self.img_cols = 256 \n","        self.channels = 3\n","        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n","\n","        # Configure data loader\n","        self.dataset_name = 'isic2016gan' #contains trainA, trainB, testA, testB\n","        self.data_loader = DataLoader(dataset_name=self.dataset_name,\n","                                      img_res=(self.img_rows, self.img_cols))\n","\n","\n","        # Calculate output shape of D (PatchGAN)\n","        patch = int(self.img_rows / 2**4)\n","        self.disc_patch = (patch, patch, 1)\n","\n","        # Number of filters in the first layer of G and D\n","        self.gf = 32\n","        self.df = 64\n","\n","        # Loss weights\n","        self.lambda_cycle = 10.0                    # Cycle-consistency loss\n","        self.lambda_id = 0.1 * self.lambda_cycle    # Identity loss\n","\n","        optimizer = Adam(0.0002, 0.5)\n","\n","        # Build and compile the discriminators\n","        self.d_A = self.build_discriminator()\n","        self.d_B = self.build_discriminator()\n","        self.d_A.compile(loss='mse',\n","            optimizer=optimizer,\n","            metrics=['accuracy'])\n","        self.d_B.compile(loss='mse',\n","            optimizer=optimizer,\n","            metrics=['accuracy'])\n","\n","        #-------------------------\n","        # Construct Computational\n","        #   Graph of Generators\n","        #-------------------------\n","\n","        # Build the generators\n","        self.g_AB = self.build_generator()\n","        self.g_BA = self.build_generator()\n","\n","        # Input images from both domains\n","        img_A = Input(shape=self.img_shape)\n","        img_B = Input(shape=self.img_shape)\n","\n","        # Translate images to the other domain\n","        fake_B = self.g_AB(img_A)\n","        fake_A = self.g_BA(img_B)\n","        # Translate images back to original domain\n","        reconstr_A = self.g_BA(fake_B)\n","        reconstr_B = self.g_AB(fake_A)\n","        # Identity mapping of images\n","        img_A_id = self.g_BA(img_A)\n","        img_B_id = self.g_AB(img_B)\n","\n","        # For the combined model we will only train the generators\n","        self.d_A.trainable = False\n","        self.d_B.trainable = False\n","\n","        # Discriminators determines validity of translated images\n","        valid_A = self.d_A(fake_A)\n","        valid_B = self.d_B(fake_B)\n","\n","        # Combined model trains generators to fool discriminators\n","        self.combined = Model(inputs=[img_A, img_B],\n","                              outputs=[ valid_A, valid_B,\n","                                        reconstr_A, reconstr_B,\n","                                        img_A_id, img_B_id ])\n","        self.combined.compile(loss=['mse', 'mse',\n","                                    'mae', 'mae',\n","                                    'mae', 'mae'],\n","                            loss_weights=[  1, 1,\n","                                            self.lambda_cycle, self.lambda_cycle,\n","                                            self.lambda_id, self.lambda_id ],\n","                            optimizer=optimizer)\n","\n","    def build_generator(self):\n","        \"\"\"U-Net Generator\"\"\"\n","\n","        def conv2d(layer_input, filters, f_size=4):\n","            \"\"\"Layers used during downsampling\"\"\"\n","            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n","            d = LeakyReLU(alpha=0.2)(d)\n","            d = InstanceNormalization()(d)\n","            return d\n","\n","        def deconv2d(layer_input, skip_input, filters, f_size=4, dropout_rate=0):\n","            \"\"\"Layers used during upsampling\"\"\"\n","            u = UpSampling2D(size=2)(layer_input)\n","            u = Conv2D(filters, kernel_size=f_size, strides=1, padding='same', activation='relu')(u)\n","            if dropout_rate:\n","                u = Dropout(dropout_rate)(u)\n","            u = InstanceNormalization()(u)\n","            u = Concatenate()([u, skip_input])\n","            return u\n","\n","        # Image input\n","        d0 = Input(shape=self.img_shape)\n","\n","        # Downsampling\n","        d1 = conv2d(d0, self.gf)\n","        d2 = conv2d(d1, self.gf*2)\n","        d3 = conv2d(d2, self.gf*4)\n","        d4 = conv2d(d3, self.gf*8)\n","\n","        # Upsampling\n","        u1 = deconv2d(d4, d3, self.gf*4)\n","        u2 = deconv2d(u1, d2, self.gf*2)\n","        u3 = deconv2d(u2, d1, self.gf)\n","\n","        u4 = UpSampling2D(size=2)(u3)\n","        output_img = Conv2D(self.channels, kernel_size=4, strides=1, padding='same', activation='tanh')(u4)\n","\n","        return Model(d0, output_img)\n","\n","    def build_discriminator(self):\n","\n","        def d_layer(layer_input, filters, f_size=4, normalization=True):\n","            \"\"\"Discriminator layer\"\"\"\n","            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n","            d = LeakyReLU(alpha=0.2)(d)\n","            if normalization:\n","                d = InstanceNormalization()(d)\n","            return d\n","\n","        img = Input(shape=self.img_shape)\n","\n","        d1 = d_layer(img, self.df, normalization=False)\n","        d2 = d_layer(d1, self.df*2)\n","        d3 = d_layer(d2, self.df*4)\n","        d4 = d_layer(d3, self.df*8)\n","\n","        validity = Conv2D(1, kernel_size=4, strides=1, padding='same')(d4)\n","\n","        return Model(img, validity)\n","\n","    def train(self, epochs, batch_size=1, sample_interval=50):\n","\n","        start_time = datetime.datetime.now()\n","\n","        # Adversarial loss ground truths\n","        valid = np.ones((batch_size,) + self.disc_patch)\n","        fake = np.zeros((batch_size,) + self.disc_patch)\n","        \n","        # Make a log file\n","        record_df = pd.DataFrame(columns=['epoch', 'd_Loss', 'accuracy', 'g_loss', 'adv', 'recon', 'id', 'elapsed_time'])\n","\n","        for epoch in range(epochs):\n","            for batch_i, (imgs_A, imgs_B) in enumerate(self.data_loader.load_batch(batch_size)):\n","\n","                # ----------------------\n","                #  Train Discriminators\n","                # ----------------------\n","\n","                # Translate images to opposite domain\n","                fake_B = self.g_AB.predict(imgs_A)\n","                fake_A = self.g_BA.predict(imgs_B)\n","\n","                # Train the discriminators (original images = real / translated = Fake)\n","                dA_loss_real = self.d_A.train_on_batch(imgs_A, valid)\n","                dA_loss_fake = self.d_A.train_on_batch(fake_A, fake)\n","                dA_loss = 0.5 * np.add(dA_loss_real, dA_loss_fake)\n","\n","                dB_loss_real = self.d_B.train_on_batch(imgs_B, valid)\n","                dB_loss_fake = self.d_B.train_on_batch(fake_B, fake)\n","                dB_loss = 0.5 * np.add(dB_loss_real, dB_loss_fake)\n","\n","                # Total disciminator loss\n","                d_loss = 0.5 * np.add(dA_loss, dB_loss)\n","\n","\n","                # ------------------\n","                #  Train Generators\n","                # ------------------\n","\n","                # Train the generators\n","                g_loss = self.combined.train_on_batch([imgs_A, imgs_B],\n","                                                        [valid, valid,\n","                                                        imgs_A, imgs_B,\n","                                                        imgs_A, imgs_B])\n","\n","                elapsed_time = datetime.datetime.now() - start_time\n","\n","                # Plot the progress\n","                #print (\"[Epoch %d/%d] [Batch %d/%d] [D loss: %f, acc: %3d%%] [G loss: %05f, adv: %05f, recon: %05f, id: %05f] time: %s \" \\\n","                #                                                        % ( epoch, epochs,\n","                #                                                            batch_i, self.data_loader.n_batches,\n","                #                                                            d_loss[0], 100*d_loss[1],\n","                #                                                            g_loss[0],\n","                #                                                            np.mean(g_loss[1:3]),\n","                #                                                            np.mean(g_loss[3:5]),\n","                #                                                            np.mean(g_loss[5:6]),\n","                #                                                            elapsed_time))\n","\n","                # If at save interval => save generated image samples\n","                if batch_i % sample_interval == 0:\n","                    self.sample_images(epoch, batch_i)\n","            \n","            \n","            # Print updates\n","            print(epoch,\"--------\", d_loss[0], g_loss[0], 100*d_loss[1])\n","\n","            # Log metrics at end of epoch            \n","            new_row = {'epoch': epoch, 'd_Loss': d_loss[0], 'accuracy': 100*d_loss[1], 'g_loss': g_loss[0], 'adv': np.mean(g_loss[1:3]), 'recon': np.mean(g_loss[3:5]), 'id': np.mean(g_loss[5:6]), 'elapsed_time': elapsed_time}\n","                                      \n","            record_df = record_df.append(new_row, ignore_index=True)\n","            record_df.to_csv(\"{}/record.csv\".format(base_path), index=0)\n","            \n","            # Save file at end of epoch.\n","            print(\"Saving model at {} epoch.\".format(epoch))\n","            self.g_AB.save(filepath='{}/saved_model/{}'.format(base_path, \"g_AB.h5\"))\n","            keras.callbacks.ModelCheckpoint(filepath='{}/saved_model/{}'.format(base_path, \"g_AB.h5\"), verbose=1,save_best_only=True)\n","\n","            self.g_BA.save(filepath='{}/saved_model/{}'.format(base_path, \"g_BA.h5\"))\n","            keras.callbacks.ModelCheckpoint(filepath='{}/saved_model/{}'.format(base_path, \"g_BA.h5\"), verbose=1,save_best_only=True)\n","\n","            self.combined.save(filepath='{}/saved_model/{}'.format(base_path, \"model.h5\"))\n","            keras.callbacks.ModelCheckpoint(filepath='{}/saved_model/{}'.format(base_path, \"model.h5\"), verbose=1,save_best_only=True)   \n","            \n","        \n","        print(\"Training finished...\")\n","        print(\"Models Saved!\")\n","\n","\n","    def sample_images(self, epoch, batch_i):\n","        os.makedirs('{}/images/%s'.format(base_path) % self.dataset_name, exist_ok=True)\n","        r, c = 2, 3\n","\n","        imgs_A = self.data_loader.load_data(domain=\"A\", batch_size=1, is_testing=True)\n","        imgs_B = self.data_loader.load_data(domain=\"B\", batch_size=1, is_testing=True)\n","\n","        # Demo (for GIF)\n","        #imgs_A = self.data_loader.load_img('datasets/apple2orange/testA/n07740461_1541.jpg')\n","        #imgs_B = self.data_loader.load_img('datasets/apple2orange/testB/n07749192_4241.jpg')\n","\n","        # Translate images to the other domain\n","        fake_B = self.g_AB.predict(imgs_A)\n","        fake_A = self.g_BA.predict(imgs_B)\n","        # Translate back to original domain\n","        reconstr_A = self.g_BA.predict(fake_B)\n","        reconstr_B = self.g_AB.predict(fake_A)\n","\n","        gen_imgs = np.concatenate([imgs_A, fake_B, reconstr_A, imgs_B, fake_A, reconstr_B])\n","\n","        # Rescale images 0 - 1\n","        gen_imgs = 0.5 * gen_imgs + 0.5\n","\n","        titles = ['Original', 'Translated', 'Reconstructed']\n","        fig, axs = plt.subplots(r, c)\n","        cnt = 0\n","        for i in range(r):\n","            for j in range(c):\n","                axs[i,j].imshow(gen_imgs[cnt])\n","                axs[i, j].set_title(titles[j])\n","                axs[i,j].axis('off')\n","                cnt += 1\n","        fig.savefig(\"{}/images/%s/%d_%d.png\".format(base_path) % (self.dataset_name, epoch, batch_i))\n","        plt.close()\n","\n","\n","if __name__ == '__main__':\n","    \n","    start_time = time.time()\n","    \n","    gan = CycleGAN()\n","    print(\"Training..\")\n","    gan.train(epochs=100, batch_size=1, sample_interval=500)\n","    \n","    end_time = time.time()\n","    print(\"--- Time taken to train : %s hours ---\" % ((end_time - start_time)//3600))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n","\n","Training..\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:109: DeprecationWarning: `imread` is deprecated!\n","`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n","Use ``imageio.imread`` instead.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:69: DeprecationWarning: `imresize` is deprecated!\n","`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n","Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:70: DeprecationWarning: `imresize` is deprecated!\n","`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n","Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n","  'Discrepancy between trainable weights and collected trainable'\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n","  'Discrepancy between trainable weights and collected trainable'\n","/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n","  'Discrepancy between trainable weights and collected trainable'\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:109: DeprecationWarning: `imread` is deprecated!\n","`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n","Use ``imageio.imread`` instead.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:35: DeprecationWarning: `imresize` is deprecated!\n","`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n","Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:69: DeprecationWarning: `imresize` is deprecated!\n","`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n","Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:70: DeprecationWarning: `imresize` is deprecated!\n","`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n","Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n","/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n","  'Discrepancy between trainable weights and collected trainable'\n"],"name":"stderr"},{"output_type":"stream","text":["0 -------- 0.52340466 6.472894 50.29296875\n","Saving model at 0 epoch.\n","1 -------- 0.30383947 5.3079305 41.2109375\n","Saving model at 1 epoch.\n","2 -------- 0.3393489 4.5548596 28.3203125\n","Saving model at 2 epoch.\n","3 -------- 0.29852074 5.5750527 41.50390625\n","Saving model at 3 epoch.\n","4 -------- 0.2701213 4.046838 49.51171875\n","Saving model at 4 epoch.\n","5 -------- 0.307732 4.0499554 35.83984375\n","Saving model at 5 epoch.\n","6 -------- 0.498761 4.9771185 64.6484375\n","Saving model at 6 epoch.\n","7 -------- 0.14927341 4.944365 90.33203125\n","Saving model at 7 epoch.\n","8 -------- 0.29209352 3.703819 43.06640625\n","Saving model at 8 epoch.\n","9 -------- 0.18384472 2.4874434 86.5234375\n","Saving model at 9 epoch.\n","10 -------- 0.23455486 2.7792127 66.6015625\n","Saving model at 10 epoch.\n","11 -------- 0.23253539 3.6937163 58.69140625\n","Saving model at 11 epoch.\n","12 -------- 0.22249857 4.021728 61.9140625\n","Saving model at 12 epoch.\n","13 -------- 0.29596788 2.4405565 43.9453125\n","Saving model at 13 epoch.\n","14 -------- 0.30985874 2.6527004 33.30078125\n","Saving model at 14 epoch.\n","15 -------- 0.33072674 3.0674343 19.7265625\n","Saving model at 15 epoch.\n","16 -------- 0.26887947 2.2756774 42.87109375\n","Saving model at 16 epoch.\n","17 -------- 0.2533974 3.7315488 48.6328125\n","Saving model at 17 epoch.\n","18 -------- 0.264894 4.2386994 59.27734375\n","Saving model at 18 epoch.\n","19 -------- 0.37429518 2.3578408 9.5703125\n","Saving model at 19 epoch.\n","20 -------- 0.26060158 3.2265503 63.4765625\n","Saving model at 20 epoch.\n","21 -------- 0.30561733 2.0870428 10.9375\n","Saving model at 21 epoch.\n","22 -------- 0.29432434 2.279875 27.734375\n","Saving model at 22 epoch.\n","23 -------- 0.1846481 4.3770328 83.69140625\n","Saving model at 23 epoch.\n","24 -------- 0.26470748 3.239723 43.84765625\n","Saving model at 24 epoch.\n","25 -------- 0.29823518 2.4255793 51.171875\n","Saving model at 25 epoch.\n","26 -------- 0.33586115 2.3775382 30.078125\n","Saving model at 26 epoch.\n","27 -------- 0.26062527 1.7249316 39.6484375\n","Saving model at 27 epoch.\n","28 -------- 0.2084631 3.2276142 74.21875\n","Saving model at 28 epoch.\n","29 -------- 0.20715463 2.8398647 61.328125\n","Saving model at 29 epoch.\n","30 -------- 0.17568551 2.767535 68.9453125\n","Saving model at 30 epoch.\n","31 -------- 0.23709519 1.6854663 54.296875\n","Saving model at 31 epoch.\n","32 -------- 0.23359236 2.8003483 63.18359375\n","Saving model at 32 epoch.\n","33 -------- 0.16013533 2.565086 78.90625\n","Saving model at 33 epoch.\n","34 -------- 0.22500896 2.4997356 71.484375\n","Saving model at 34 epoch.\n","35 -------- 0.34762883 1.8665048 26.46484375\n","Saving model at 35 epoch.\n","36 -------- 0.2099945 1.5824523 60.3515625\n","Saving model at 36 epoch.\n","37 -------- 0.22351164 2.0704126 66.89453125\n","Saving model at 37 epoch.\n","38 -------- 0.2699765 1.9679967 35.64453125\n","Saving model at 38 epoch.\n","39 -------- 0.2971391 2.6698096 24.4140625\n","Saving model at 39 epoch.\n","40 -------- 0.20981796 2.1585498 76.26953125\n","Saving model at 40 epoch.\n","41 -------- 0.25840494 2.2456467 52.34375\n","Saving model at 41 epoch.\n","42 -------- 0.22145152 2.283848 66.9921875\n","Saving model at 42 epoch.\n","43 -------- 0.32566765 2.7031698 22.4609375\n","Saving model at 43 epoch.\n","44 -------- 0.16892587 2.741906 70.1171875\n","Saving model at 44 epoch.\n","45 -------- 0.17931089 2.438061 81.4453125\n","Saving model at 45 epoch.\n","46 -------- 0.20856416 2.1408064 70.99609375\n","Saving model at 46 epoch.\n","47 -------- 0.2777413 1.8473773 42.96875\n","Saving model at 47 epoch.\n","48 -------- 0.16153207 2.8451712 79.8828125\n","Saving model at 48 epoch.\n","49 -------- 0.21999803 1.6421359 60.64453125\n","Saving model at 49 epoch.\n","50 -------- 0.2780305 1.6988688 32.51953125\n","Saving model at 50 epoch.\n","51 -------- 0.156345 2.4233885 85.83984375\n","Saving model at 51 epoch.\n","52 -------- 0.15027595 2.6940901 91.015625\n","Saving model at 52 epoch.\n","53 -------- 0.24764474 1.6982777 46.09375\n","Saving model at 53 epoch.\n","54 -------- 0.2566499 2.0973303 49.21875\n","Saving model at 54 epoch.\n","55 -------- 0.24955584 2.2604957 53.7109375\n","Saving model at 55 epoch.\n","56 -------- 0.34847087 1.5043323 42.96875\n","Saving model at 56 epoch.\n","57 -------- 0.19098626 2.1769269 84.66796875\n","Saving model at 57 epoch.\n","58 -------- 0.32533902 1.2456553 19.62890625\n","Saving model at 58 epoch.\n","59 -------- 0.24869555 2.162893 52.83203125\n","Saving model at 59 epoch.\n","60 -------- 0.26936102 1.8017166 56.73828125\n","Saving model at 60 epoch.\n","61 -------- 0.25378 2.2405803 51.3671875\n","Saving model at 61 epoch.\n","62 -------- 0.22175573 1.7215959 69.62890625\n","Saving model at 62 epoch.\n","63 -------- 0.2732202 1.6365447 48.6328125\n","Saving model at 63 epoch.\n","64 -------- 0.12736094 2.2528381 90.625\n","Saving model at 64 epoch.\n","65 -------- 0.17866662 1.5862634 66.796875\n","Saving model at 65 epoch.\n","66 -------- 0.1510365 2.2289047 87.6953125\n","Saving model at 66 epoch.\n","67 -------- 0.4017588 1.8155725 16.89453125\n","Saving model at 67 epoch.\n","68 -------- 0.10737693 2.6639907 92.67578125\n","Saving model at 68 epoch.\n","69 -------- 0.26112247 2.0650783 43.26171875\n","Saving model at 69 epoch.\n","70 -------- 0.19419612 2.5845034 75.09765625\n","Saving model at 70 epoch.\n","71 -------- 0.31304616 1.6597462 46.19140625\n","Saving model at 71 epoch.\n","72 -------- 0.14302842 2.7844987 76.171875\n","Saving model at 72 epoch.\n","73 -------- 0.2842175 1.7982569 41.015625\n","Saving model at 73 epoch.\n","74 -------- 0.1576677 2.4670172 88.18359375\n","Saving model at 74 epoch.\n","75 -------- 0.24114725 1.4568076 58.984375\n","Saving model at 75 epoch.\n","76 -------- 0.35495922 1.6362721 10.25390625\n","Saving model at 76 epoch.\n","77 -------- 0.29270315 1.718946 28.80859375\n","Saving model at 77 epoch.\n","78 -------- 0.27777684 1.7519513 45.01953125\n","Saving model at 78 epoch.\n","79 -------- 0.14923276 2.15445 77.44140625\n","Saving model at 79 epoch.\n","80 -------- 0.3099876 1.6814034 36.328125\n","Saving model at 80 epoch.\n","81 -------- 0.177218 2.1313384 76.26953125\n","Saving model at 81 epoch.\n","82 -------- 0.26357567 2.0903847 41.9921875\n","Saving model at 82 epoch.\n","83 -------- 0.2732409 2.4438853 44.921875\n","Saving model at 83 epoch.\n","84 -------- 0.21314836 2.3154535 72.75390625\n","Saving model at 84 epoch.\n","85 -------- 0.20518771 1.4911228 77.5390625\n","Saving model at 85 epoch.\n","86 -------- 0.26062635 1.6833127 52.734375\n","Saving model at 86 epoch.\n","87 -------- 0.1737475 2.2520866 72.65625\n","Saving model at 87 epoch.\n","88 -------- 0.23403016 1.7256556 65.52734375\n","Saving model at 88 epoch.\n","89 -------- 0.22372729 1.5870061 64.6484375\n","Saving model at 89 epoch.\n","90 -------- 0.2423659 1.5383798 57.03125\n","Saving model at 90 epoch.\n","91 -------- 0.22398701 1.82489 68.1640625\n","Saving model at 91 epoch.\n","92 -------- 0.26159054 1.3698765 46.77734375\n","Saving model at 92 epoch.\n","93 -------- 0.27091545 1.5919163 44.921875\n","Saving model at 93 epoch.\n","94 -------- 0.23207343 1.4288518 59.47265625\n","Saving model at 94 epoch.\n","95 -------- 0.31854987 1.546739 54.58984375\n","Saving model at 95 epoch.\n","96 -------- 0.34597895 1.4869356 30.37109375\n","Saving model at 96 epoch.\n","97 -------- 0.24493827 1.7624781 48.92578125\n","Saving model at 97 epoch.\n","98 -------- 0.2580818 1.3527294 48.2421875\n","Saving model at 98 epoch.\n","99 -------- 0.13102639 1.9821279 91.9921875\n","Saving model at 99 epoch.\n","Training finished...\n","Models Saved!\n","--- Time taken to train : 3.0 hours ---\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8MWnwzyDvFJ5","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}